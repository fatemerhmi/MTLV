mlflow:
  experiment_name: reuters_experiments
  run_name: signlehead_bert
  tracking_uri: mlruns

dataset: 
  reuters:
    root: ./data
    data_split: True # True: train, test | False: train, test, val
    data_path: reuters/reuters_train.csv
    # split_path: openI/cheXpertLabels
    use_data_loader: True

model: 
  bert:
    model_name: bert-base-uncased
    freeze: True
    
training:
  # type: multihead_cls
  type: singlehead_cls
  epoch : 5
  batch_size : 16
  use_cuda : True

head: 
  single-head:
    heads: MultiLabelCLS

# head: 
#   single-head: # or multi-task 
#   multi-head:
#     # count: 3
#     heads: MultiLabelCLS
#     heads_index : [[0,1,2,3], [4,5,6], [7,8,9,10]]

tokenizer:
  bert:
    name: bert_base_uncased
    padding: max_length    # to pad to the longest sequence in the batch
    truncation: True  # truncate to a maximum length specified by the max_length
    max_length : 128

optimizer:
  adam:
    name: AdamW
    lr: 0.00002