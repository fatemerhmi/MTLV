{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  dataset  ] twentynewsgroup directory already exists, loading...\n",
      "[  dataset  ] loaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pyunpack import Archive\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    " \n",
    "def create_new_column(df, column_name):\n",
    "    df[column_name] = df.apply(lambda row: \\\n",
    "                                        1 if column_name in row['labels'] \\\n",
    "                                        else 0, \\\n",
    "                                        axis=1)\n",
    "    return df\n",
    "\n",
    "def make_csv(path):\n",
    "    all_data = []\n",
    "    for label in tqdm(labels):\n",
    "        instances_in_a_label = os.listdir (f\"{path}/{label}\")\n",
    "        for item in instances_in_a_label:\n",
    "            f = open(f\"{DATA_DIR}/{path}/{label}/{item}\", \"r\", encoding='utf-8',errors='ignore')\n",
    "            raw_data = f.read()\n",
    "            all_data.append([item, raw_data, label])\n",
    "    all_data = np.asarray(all_data)\n",
    "    df = pd.DataFrame(all_data, columns=[\"id\", \"text\", \"label\"])\n",
    "    return df\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "if os.path.exists(f\"{DATA_DIR}/twentynewsgroup\"):\n",
    "    #--------load dataframe\n",
    "    print(\"[  dataset  ] twentynewsgroup directory already exists, loading...\")\n",
    "    train_val_df = pd.read_csv(f\"{DATA_DIR}/twentynewsgroup/twentynewsgroup_train.csv\", encoding='utf-8')\n",
    "    # for index, row in train_val_df.iterrows():\n",
    "    #     try:\n",
    "    #         ast.literal_eval(row['labels'])\n",
    "    #     except:\n",
    "    #         print(row.labels)\n",
    "    train_val_df['labels'] = train_val_df.apply(lambda row: ast.literal_eval(row['labels']), axis=1)\n",
    "\n",
    "    test_df = pd.read_csv(f\"{DATA_DIR}/twentynewsgroup/twentynewsgroup_test.csv\", encoding='utf-8')\n",
    "    test_df['labels'] = test_df.apply(lambda row: ast.literal_eval(row['labels']), axis=1)\n",
    "\n",
    "    # #--------loading and storing labels to mlflow\n",
    "    labels = np.load(f\"{DATA_DIR}/twentynewsgroup/labels.npy\")\n",
    "    num_labels = len(labels)\n",
    "    # mlflowLogger.store_param(\"col_names\", labels)\n",
    "    # mlflowLogger.store_param(\"num_labels\", num_labels)\n",
    "    print(\"[  dataset  ] loaded!\")\n",
    "else:\n",
    "    os.makedirs(f\"{DATA_DIR}/twentynewsgroup\")\n",
    "    \n",
    "    print(\"[  dataset  ] twentynewsgroup dataset is being downloaded...\")\n",
    "    os.system(f'wget -N -P {DATA_DIR}/twentynewsgroup http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz')\n",
    "\n",
    "    # data/twentynewsgroup/20news-bydate.tar.gz\n",
    "    print(\"[  dataset  ] Extracting twentynewsgroup dataset...\")\n",
    "    directory_to_extract_to = f\"{DATA_DIR}/twentynewsgroup/\"\n",
    "    Archive(f\"{DATA_DIR}/twentynewsgroup/20news-bydate.tar.gz\").extractall(directory_to_extract_to)\n",
    "    os.system(f\"rm {DATA_DIR}/twentynewsgroup/20news-bydate.tar.gz\")\n",
    "\n",
    "    #------storing label details to mlflow and npy file\n",
    "    labels = os.listdir (f\"{DATA_DIR}/twentynewsgroup/20news-bydate-train\")\n",
    "    if \".DS_Store\" in labels:\n",
    "        labels.remove(\".DS_Store\")\n",
    "    \n",
    "    np.save(f\"{DATA_DIR}/twentynewsgroup/labels.npy\", labels)\n",
    "    num_labels = len(labels)\n",
    "    # mlflowLogger.store_param(\"col_names\", labels)\n",
    "    # mlflowLogger.store_param(\"num_labels\", num_labels)\n",
    "\n",
    "    #------convert the files to a dataframe \n",
    "    train_val_df = make_csv(f\"{DATA_DIR}/twentynewsgroup/20news-bydate-train\")\n",
    "    test_df = make_csv(f\"{DATA_DIR}/twentynewsgroup/20news-bydate-test\")\n",
    "\n",
    "    os.system(f\"rm -r {DATA_DIR}/twentynewsgroup/20news-bydate-*\")\n",
    "\n",
    "     #------preprocessing the labels\n",
    "    tqdm.pandas()\n",
    "    print(\"\\n[  dataset  ] twentynewsgroup preprocessing of labels begin...\")\n",
    "    train_val_df[\"labels\"] = train_val_df.progress_apply(lambda row: train_val_df.loc[train_val_df['id'] == row['id']].label.tolist(), axis=1)\n",
    "    test_df[\"labels\"] = test_df.progress_apply(lambda row: test_df.loc[test_df['id'] == row['id']].label.tolist(), axis=1)\n",
    "\n",
    "    os.system(f\"rm -r {DATA_DIR}/twentynewsgroup/20news-bydate-*\")\n",
    "\n",
    "    #------remove duplicate rows\n",
    "    train_val_df.drop_duplicates('id', inplace=True)\n",
    "    test_df.drop_duplicates('id', inplace=True)\n",
    "\n",
    "    #------bring labels to seperate columns\n",
    "    for label in tqdm(labels):\n",
    "        train_val_df = create_new_column(train_val_df, label)\n",
    "        test_df = create_new_column(test_df, label)\n",
    "\n",
    "    train_val_df.drop(['labels', \"label\"],inplace=True, axis=1)\n",
    "    test_df.drop(['labels', \"label\"],inplace=True, axis=1)\n",
    "\n",
    "    train_val_df['labels'] = train_val_df.apply(lambda row: row[labels].to_list(), axis=1)\n",
    "    test_df['labels'] = test_df.apply(lambda row: row[labels].to_list(), axis=1)\n",
    "\n",
    "    train_val_df.drop(labels, inplace=True, axis=1)\n",
    "    test_df.drop(labels, inplace=True, axis=1)\n",
    "\n",
    "    #------remove back quote from text\n",
    "    train_val_df['text'] = train_val_df.apply(lambda row: row.text.replace(\"`\", \"'\"), axis=1)\n",
    "    test_df['text'] = test_df.apply(lambda row: row.text.replace(\"`\", \"'\"), axis=1)\n",
    "\n",
    "    #-------save the datafarme\n",
    "    train_val_df.to_csv(f'{DATA_DIR}/twentynewsgroup/twentynewsgroup_train.csv', index=False)\n",
    "    test_df.to_csv(f'{DATA_DIR}/twentynewsgroup/twentynewsgroup_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
